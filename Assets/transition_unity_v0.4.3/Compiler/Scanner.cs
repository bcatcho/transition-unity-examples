
#line 1 "Scanner.rl.cs"
// This file is AUTOGENERATED with RAGEL
// !!DO NOT EDIT!! Change the RL file and compile with Ragel
// See the ScannerGenerator directory.
// http://www.colm.net/open-source/ragel/
using System.Collections.Generic;
using Transition.Compiler.Tokens;

namespace Transition.Compiler
{
   /// <summary>
   /// Scanner performs lexical analysis on a string of characters and
   /// and emits a string of tokens for the Parser to analyze.
   /// </summary>
   public class Scanner
   {
      int _lineNumber = 0;
      bool _tokenUncommitted;
      int _tokenStart { get { return _token.StartIndex; } }
      Token _token;
      private List<Token> _tokens;

      // ragel properties
      private int eof;
      private int cs;
      private int p;

      private void StartToken(TokenType tokenType)
      {
        #if PARSER_LOGGING
        Log(string.Format("start {0}", tokenType));
        #endif
        _token = new Token {
            LineNumber = _lineNumber,
            StartIndex = p,
            TokenType = tokenType
        };
        _tokenUncommitted = true;
      }

      private void StartOperatorToken(TokenOperator tokenOperator)
      {
        #if PARSER_LOGGING
        Log(string.Format("start {0}", tokenOperator));
        #endif
        _token = new Token {
            LineNumber = _lineNumber,
            StartIndex = p,
            Operator = tokenOperator,
            TokenType = TokenType.Operator,
        };
        _tokenUncommitted = true;
      }

      #if PARSER_LOGGING
      private void Log(string msg) {
        Console.WriteLine(string.Format("{0} {1}", p, msg));
      }
      #endif

      private void EmitToken() {
        #if PARSER_LOGGING
        Log(string.Format("emit {0}", _token.TokenType));
        #endif
        _token.Length = p - _tokenStart;
        _tokens.Add(_token);
        _tokenUncommitted = false;
      }

      private void EmitNewLine() {
        _token.TokenType = TokenType.NewLine;
        #if PARSER_LOGGING
        Log(string.Format("emit {0}", _token.TokenType));
        #endif
        _tokens.Add(_token);
        _tokenUncommitted = false;
      }

      private void SetKeyword(TokenKeyword tokenKeyword) {
        _token.Keyword = tokenKeyword;
      }

      private void CommitLastToken() {
        if (_tokenUncommitted) {
          EmitToken();
        }
      }

      
#line 92 "tmp/Scanner.cs"
static readonly sbyte[] _Scanner_actions =  new sbyte [] {
	0, 1, 0, 1, 1, 1, 2, 1, 
	3, 1, 4, 1, 5, 1, 6, 1, 
	7, 1, 8, 1, 9, 1, 10, 1, 
	11, 1, 12, 2, 1, 0, 2, 1, 
	2, 2, 1, 3, 2, 1, 5, 2, 
	6, 1
};

static readonly short[] _Scanner_key_offsets =  new short [] {
	0, 0, 13, 15, 17, 21, 30, 39, 
	40, 45, 50, 52, 54, 60, 75, 77, 
	79, 81, 81, 86, 88, 89, 90, 91, 
	97, 108, 123, 137, 151, 166, 168, 170, 
	177, 193, 206, 219, 221, 223, 223, 235, 
	240, 241, 246, 251, 253, 255, 261, 272, 
	287, 302, 317, 333, 335, 337, 337, 337, 
	339, 341, 341, 341, 355, 362, 363, 364, 
	365, 366, 367, 368, 369, 370, 371, 372, 
	373, 374, 375, 376, 377, 377, 377, 390, 
	405, 420, 435, 451, 466
};

static readonly char[] _Scanner_trans_keys =  new char [] {
	'\u0020', '\u0022', '\u0023', '\u0027', '\u002d', '\u0040', '\u005f', '\u0009', 
	'\u000d', '\u0041', '\u005a', '\u0061', '\u007a', '\u0022', '\u005c', '\u0022', 
	'\u005c', '\u0020', '\u003a', '\u0009', '\u000d', '\u0020', '\u002d', '\u005f', 
	'\u0009', '\u000d', '\u0041', '\u005a', '\u0061', '\u007a', '\u0020', '\u002d', 
	'\u005f', '\u0009', '\u000d', '\u0041', '\u005a', '\u0061', '\u007a', '\u003e', 
	'\u0020', '\u0022', '\u0027', '\u0009', '\u000d', '\u0020', '\u0022', '\u0027', 
	'\u0009', '\u000d', '\u0022', '\u005c', '\u0022', '\u005c', '\u000a', '\u000d', 
	'\u0020', '\u0023', '\u0009', '\u000c', '\u000a', '\u000d', '\u0020', '\u0022', 
	'\u0023', '\u0027', '\u002d', '\u0040', '\u005f', '\u0009', '\u000c', '\u0041', 
	'\u005a', '\u0061', '\u007a', '\u000a', '\u000d', '\u0027', '\u005c', '\u0027', 
	'\u005c', '\u0065', '\u006d', '\u006f', '\u0072', '\u0073', '\u006e', '\u0078', 
	'\u0074', '\u0065', '\u0072', '\u000a', '\u000d', '\u0020', '\u0023', '\u0009', 
	'\u000c', '\u000a', '\u000d', '\u0020', '\u0023', '\u005f', '\u0009', '\u000c', 
	'\u0041', '\u005a', '\u0061', '\u007a', '\u000a', '\u000d', '\u0020', '\u0022', 
	'\u0023', '\u0027', '\u002d', '\u0040', '\u005f', '\u0009', '\u000c', '\u0041', 
	'\u005a', '\u0061', '\u007a', '\u000a', '\u000d', '\u0020', '\u0023', '\u002d', 
	'\u005f', '\u0009', '\u000c', '\u0030', '\u0039', '\u0041', '\u005a', '\u0061', 
	'\u007a', '\u000a', '\u000d', '\u0020', '\u0022', '\u0023', '\u0027', '\u002d', 
	'\u005f', '\u0009', '\u000c', '\u0041', '\u005a', '\u0061', '\u007a', '\u000a', 
	'\u000d', '\u0020', '\u0022', '\u0023', '\u0027', '\u002d', '\u0040', '\u005f', 
	'\u0009', '\u000c', '\u0041', '\u005a', '\u0061', '\u007a', '\u0022', '\u005c', 
	'\u0022', '\u005c', '\u000a', '\u000d', '\u0020', '\u0023', '\u003a', '\u0009', 
	'\u000c', '\u000a', '\u000d', '\u0020', '\u0022', '\u0023', '\u0027', '\u002d', 
	'\u003a', '\u0040', '\u005f', '\u0009', '\u000c', '\u0041', '\u005a', '\u0061', 
	'\u007a', '\u000a', '\u000d', '\u0020', '\u0023', '\u005f', '\u0009', '\u000c', 
	'\u0030', '\u0039', '\u0041', '\u005a', '\u0061', '\u007a', '\u000a', '\u000d', 
	'\u0020', '\u0022', '\u0023', '\u0027', '\u005f', '\u0009', '\u000c', '\u0041', 
	'\u005a', '\u0061', '\u007a', '\u0027', '\u005c', '\u0027', '\u005c', '\u0020', 
	'\u002d', '\u003a', '\u005f', '\u0009', '\u000d', '\u0030', '\u0039', '\u0041', 
	'\u005a', '\u0061', '\u007a', '\u0020', '\u002d', '\u003a', '\u0009', '\u000d', 
	'\u003e', '\u0020', '\u0022', '\u0027', '\u0009', '\u000d', '\u0020', '\u0022', 
	'\u0027', '\u0009', '\u000d', '\u0022', '\u005c', '\u0022', '\u005c', '\u000a', 
	'\u000d', '\u0020', '\u0023', '\u0009', '\u000c', '\u000a', '\u000d', '\u0020', 
	'\u0023', '\u005f', '\u0009', '\u000c', '\u0041', '\u005a', '\u0061', '\u007a', 
	'\u000a', '\u000d', '\u0020', '\u0022', '\u0023', '\u0027', '\u002d', '\u0040', 
	'\u005f', '\u0009', '\u000c', '\u0041', '\u005a', '\u0061', '\u007a', '\u000a', 
	'\u000d', '\u0020', '\u0023', '\u002d', '\u003a', '\u005f', '\u0009', '\u000c', 
	'\u0030', '\u0039', '\u0041', '\u005a', '\u0061', '\u007a', '\u000a', '\u000d', 
	'\u0020', '\u0022', '\u0023', '\u0027', '\u002d', '\u003a', '\u005f', '\u0009', 
	'\u000c', '\u0041', '\u005a', '\u0061', '\u007a', '\u000a', '\u000d', '\u0020', 
	'\u0022', '\u0023', '\u0027', '\u002d', '\u003a', '\u0040', '\u005f', '\u0009', 
	'\u000c', '\u0041', '\u005a', '\u0061', '\u007a', '\u0027', '\u005c', '\u0027', 
	'\u005c', '\u0027', '\u005c', '\u0027', '\u005c', '\u000a', '\u000d', '\u0020', 
	'\u0023', '\u002d', '\u005f', '\u0009', '\u000c', '\u0030', '\u0039', '\u0041', 
	'\u005a', '\u0061', '\u007a', '\u000a', '\u000d', '\u0020', '\u0023', '\u002d', 
	'\u0009', '\u000c', '\u0069', '\u0074', '\u0061', '\u0063', '\u0068', '\u0069', 
	'\u006e', '\u0065', '\u006e', '\u0075', '\u006e', '\u0074', '\u0061', '\u0074', 
	'\u0065', '\u0020', '\u0022', '\u0023', '\u0027', '\u002d', '\u0040', '\u005f', 
	'\u0009', '\u000d', '\u0041', '\u005a', '\u0061', '\u007a', '\u000a', '\u000d', 
	'\u0020', '\u0022', '\u0023', '\u0027', '\u002d', '\u0040', '\u005f', '\u0009', 
	'\u000c', '\u0041', '\u005a', '\u0061', '\u007a', '\u000a', '\u000d', '\u0020', 
	'\u0022', '\u0023', '\u0027', '\u002d', '\u0040', '\u005f', '\u0009', '\u000c', 
	'\u0041', '\u005a', '\u0061', '\u007a', '\u000a', '\u000d', '\u0020', '\u0022', 
	'\u0023', '\u0027', '\u002d', '\u0040', '\u005f', '\u0009', '\u000c', '\u0041', 
	'\u005a', '\u0061', '\u007a', '\u000a', '\u000d', '\u0020', '\u0022', '\u0023', 
	'\u0027', '\u002d', '\u003a', '\u0040', '\u005f', '\u0009', '\u000c', '\u0041', 
	'\u005a', '\u0061', '\u007a', '\u000a', '\u000d', '\u0020', '\u0022', '\u0023', 
	'\u0027', '\u002d', '\u0040', '\u005f', '\u0009', '\u000c', '\u0041', '\u005a', 
	'\u0061', '\u007a', '\u000a', '\u000d', '\u0020', '\u0022', '\u0023', '\u0027', 
	'\u002d', '\u003a', '\u0040', '\u005f', '\u0009', '\u000c', '\u0041', '\u005a', 
	'\u0061', '\u007a', (char) 0
};

static readonly sbyte[] _Scanner_single_lengths =  new sbyte [] {
	0, 7, 2, 2, 2, 3, 3, 1, 
	3, 3, 2, 2, 4, 9, 2, 2, 
	2, 0, 5, 2, 1, 1, 1, 4, 
	5, 9, 6, 8, 9, 2, 2, 5, 
	10, 5, 7, 2, 2, 0, 4, 3, 
	1, 3, 3, 2, 2, 4, 5, 9, 
	7, 9, 10, 2, 2, 0, 0, 2, 
	2, 0, 0, 6, 5, 1, 1, 1, 
	1, 1, 1, 1, 1, 1, 1, 1, 
	1, 1, 1, 1, 0, 0, 7, 9, 
	9, 9, 10, 9, 10
};

static readonly sbyte[] _Scanner_range_lengths =  new sbyte [] {
	0, 3, 0, 0, 1, 3, 3, 0, 
	1, 1, 0, 0, 1, 3, 0, 0, 
	0, 0, 0, 0, 0, 0, 0, 1, 
	3, 3, 4, 3, 3, 0, 0, 1, 
	3, 4, 3, 0, 0, 0, 4, 1, 
	0, 1, 1, 0, 0, 1, 3, 3, 
	4, 3, 3, 0, 0, 0, 0, 0, 
	0, 0, 0, 4, 1, 0, 0, 0, 
	0, 0, 0, 0, 0, 0, 0, 0, 
	0, 0, 0, 0, 0, 0, 3, 3, 
	3, 3, 3, 3, 3
};

static readonly short[] _Scanner_index_offsets =  new short [] {
	0, 0, 11, 14, 17, 21, 28, 35, 
	37, 42, 47, 50, 53, 59, 72, 75, 
	78, 81, 82, 88, 91, 93, 95, 97, 
	103, 112, 125, 136, 148, 161, 164, 167, 
	174, 188, 198, 209, 212, 215, 216, 225, 
	230, 232, 237, 242, 245, 248, 254, 263, 
	276, 288, 301, 315, 318, 321, 322, 323, 
	326, 329, 330, 331, 342, 349, 351, 353, 
	355, 357, 359, 361, 363, 365, 367, 369, 
	371, 373, 375, 377, 379, 380, 381, 392, 
	405, 418, 431, 445, 458
};

static readonly byte[] _Scanner_indicies =  new byte [] {
	0, 2, 3, 4, 5, 6, 7, 0, 
	7, 7, 1, 9, 10, 8, 12, 13, 
	11, 14, 15, 14, 1, 16, 17, 18, 
	16, 18, 18, 1, 19, 5, 7, 19, 
	7, 7, 1, 20, 1, 21, 22, 23, 
	21, 1, 24, 25, 26, 24, 1, 28, 
	29, 27, 31, 32, 30, 34, 35, 33, 
	3, 33, 1, 34, 37, 36, 2, 3, 
	4, 5, 6, 7, 36, 7, 7, 1, 
	34, 38, 3, 9, 40, 39, 12, 42, 
	41, 41, 43, 44, 45, 46, 47, 1, 
	48, 49, 1, 50, 1, 51, 1, 52, 
	1, 54, 55, 53, 56, 53, 1, 58, 
	59, 57, 3, 60, 57, 60, 60, 1, 
	58, 62, 61, 2, 3, 4, 5, 6, 
	63, 61, 63, 63, 1, 65, 66, 64, 
	56, 17, 67, 64, 67, 67, 67, 1, 
	69, 70, 68, 25, 3, 26, 5, 71, 
	68, 71, 71, 1, 69, 73, 72, 74, 
	3, 75, 5, 6, 76, 72, 76, 76, 
	1, 78, 79, 77, 81, 82, 80, 84, 
	85, 83, 3, 15, 83, 1, 84, 87, 
	86, 2, 3, 4, 5, 15, 6, 7, 
	86, 7, 7, 1, 65, 89, 88, 56, 
	90, 88, 90, 90, 90, 1, 69, 92, 
	91, 25, 3, 26, 71, 91, 71, 71, 
	1, 28, 94, 93, 31, 96, 95, 95, 
	97, 98, 100, 99, 97, 99, 99, 99, 
	1, 101, 102, 103, 101, 1, 104, 1, 
	105, 106, 107, 105, 1, 108, 109, 110, 
	108, 1, 112, 113, 111, 115, 116, 114, 
	118, 119, 117, 3, 117, 1, 118, 119, 
	117, 3, 71, 117, 71, 71, 1, 118, 
	121, 120, 2, 3, 4, 5, 6, 76, 
	120, 76, 76, 1, 123, 124, 122, 56, 
	98, 100, 125, 122, 125, 125, 125, 1, 
	127, 128, 126, 25, 3, 26, 102, 103, 
	71, 126, 71, 71, 1, 127, 130, 129, 
	74, 3, 75, 102, 103, 6, 76, 129, 
	76, 76, 1, 78, 132, 131, 81, 134, 
	133, 133, 114, 112, 136, 135, 115, 138, 
	137, 137, 80, 140, 141, 139, 56, 17, 
	142, 139, 142, 142, 142, 1, 34, 144, 
	143, 3, 5, 143, 1, 145, 1, 146, 
	1, 147, 1, 148, 1, 149, 1, 150, 
	1, 151, 1, 152, 1, 153, 1, 154, 
	1, 155, 1, 156, 1, 157, 1, 158, 
	1, 159, 1, 30, 11, 0, 2, 3, 
	4, 5, 6, 7, 0, 7, 7, 1, 
	34, 37, 36, 2, 3, 4, 5, 6, 
	7, 36, 7, 7, 1, 58, 62, 61, 
	2, 3, 4, 5, 6, 63, 61, 63, 
	63, 1, 69, 73, 72, 74, 3, 75, 
	5, 6, 76, 72, 76, 76, 1, 84, 
	87, 86, 2, 3, 4, 5, 15, 6, 
	7, 86, 7, 7, 1, 118, 121, 120, 
	2, 3, 4, 5, 6, 76, 120, 76, 
	76, 1, 127, 130, 129, 74, 3, 75, 
	102, 103, 6, 76, 129, 76, 76, 1, 
	0
};

static readonly sbyte[] _Scanner_trans_targs =  new sbyte [] {
	1, 0, 2, 14, 15, 7, 18, 33, 
	3, 4, 77, 3, 4, 77, 4, 5, 
	6, 7, 33, 6, 8, 9, 10, 35, 
	9, 10, 35, 11, 12, 76, 11, 12, 
	76, 12, 79, 12, 13, 13, 14, 16, 
	17, 16, 17, 19, 63, 69, 70, 72, 
	20, 61, 21, 22, 23, 24, 80, 24, 
	14, 24, 80, 24, 59, 25, 25, 26, 
	27, 81, 27, 26, 27, 81, 27, 38, 
	28, 28, 29, 51, 48, 30, 31, 58, 
	30, 31, 58, 31, 82, 31, 32, 32, 
	34, 34, 33, 34, 34, 36, 37, 36, 
	37, 39, 40, 38, 41, 39, 40, 41, 
	41, 42, 43, 55, 42, 43, 55, 44, 
	45, 54, 44, 45, 54, 46, 83, 46, 
	47, 47, 49, 84, 49, 48, 49, 84, 
	49, 50, 50, 52, 53, 52, 53, 56, 
	57, 56, 57, 60, 79, 60, 59, 60, 
	60, 62, 23, 64, 65, 66, 67, 68, 
	23, 23, 71, 23, 73, 74, 75, 23
};

static readonly sbyte[] _Scanner_trans_actions =  new sbyte [] {
	0, 0, 0, 0, 0, 5, 9, 11, 
	13, 39, 13, 0, 3, 0, 0, 7, 
	3, 30, 36, 0, 0, 3, 3, 3, 
	0, 0, 0, 13, 39, 13, 0, 3, 
	0, 0, 1, 1, 0, 1, 1, 13, 
	13, 0, 0, 0, 0, 0, 0, 0, 
	0, 0, 0, 0, 21, 3, 27, 27, 
	3, 0, 1, 1, 11, 0, 1, 11, 
	3, 27, 27, 0, 0, 1, 1, 11, 
	0, 1, 0, 0, 11, 13, 39, 13, 
	0, 3, 0, 0, 1, 1, 0, 1, 
	3, 27, 0, 0, 1, 13, 13, 0, 
	0, 3, 30, 0, 33, 0, 5, 7, 
	0, 3, 3, 3, 0, 0, 0, 13, 
	39, 13, 0, 3, 0, 0, 1, 1, 
	0, 1, 3, 27, 27, 0, 0, 1, 
	1, 0, 1, 13, 13, 0, 0, 13, 
	13, 0, 0, 3, 27, 27, 0, 0, 
	1, 0, 23, 0, 0, 0, 0, 0, 
	15, 19, 0, 25, 0, 0, 0, 17
};

const int Scanner_start = 78;
const int Scanner_first_final = 78;
const int Scanner_error = 0;

const int Scanner_en_main = 78;


#line 92 "Scanner.rl.cs"


      ///<summary>
      /// This method will perform lexical analysis on the character sequence input
      //  and will return a sequence of tokens for the Parser to analyze.
      ///</summary>
      ///<returns>
      /// A sequence of tokens that the Parser can use to Analyze.
      ///</returns>
      public List<Token> Scan(char[] data, int len)
      {
         
#line 351 "tmp/Scanner.cs"
	{
	cs = Scanner_start;
	}

#line 104 "Scanner.rl.cs"
         if (_tokens == null) {
           _tokens = new List<Token>(128);
         }
         _tokens.Clear();
         _lineNumber = 1; // start at line 1 like most text editors
         p = 0;
         int pe = len;
         eof = len;
         
#line 366 "tmp/Scanner.cs"
	{
	sbyte _klen;
	short _trans;
	int _acts;
	int _nacts;
	short _keys;

	if ( p == pe )
		goto _test_eof;
	if ( cs == 0 )
		goto _out;
_resume:
	_keys = _Scanner_key_offsets[cs];
	_trans = (short)_Scanner_index_offsets[cs];

	_klen = _Scanner_single_lengths[cs];
	if ( _klen > 0 ) {
		short _lower = _keys;
		short _mid;
		short _upper = (short) (_keys + _klen - 1);
		while (true) {
			if ( _upper < _lower )
				break;

			_mid = (short) (_lower + ((_upper-_lower) >> 1));
			if ( data[p] < _Scanner_trans_keys[_mid] )
				_upper = (short) (_mid - 1);
			else if ( data[p] > _Scanner_trans_keys[_mid] )
				_lower = (short) (_mid + 1);
			else {
				_trans += (short) (_mid - _keys);
				goto _match;
			}
		}
		_keys += (short) _klen;
		_trans += (short) _klen;
	}

	_klen = _Scanner_range_lengths[cs];
	if ( _klen > 0 ) {
		short _lower = _keys;
		short _mid;
		short _upper = (short) (_keys + (_klen<<1) - 2);
		while (true) {
			if ( _upper < _lower )
				break;

			_mid = (short) (_lower + (((_upper-_lower) >> 1) & ~1));
			if ( data[p] < _Scanner_trans_keys[_mid] )
				_upper = (short) (_mid - 2);
			else if ( data[p] > _Scanner_trans_keys[_mid+1] )
				_lower = (short) (_mid + 2);
			else {
				_trans += (short)((_mid - _keys)>>1);
				goto _match;
			}
		}
		_trans += (short) _klen;
	}

_match:
	_trans = (short)_Scanner_indicies[_trans];
	cs = _Scanner_trans_targs[_trans];

	if ( _Scanner_trans_actions[_trans] == 0 )
		goto _again;

	_acts = _Scanner_trans_actions[_trans];
	_nacts = _Scanner_actions[_acts++];
	while ( _nacts-- > 0 )
	{
		switch ( _Scanner_actions[_acts++] )
		{
	case 0:
#line 4 "ScannerDef.rl"
	{ _lineNumber++; EmitNewLine(); }
	break;
	case 1:
#line 5 "ScannerDef.rl"
	{ EmitToken(); }
	break;
	case 2:
#line 6 "ScannerDef.rl"
	{ StartOperatorToken(TokenOperator.Transition); }
	break;
	case 3:
#line 7 "ScannerDef.rl"
	{ StartOperatorToken(TokenOperator.Assign); }
	break;
	case 4:
#line 8 "ScannerDef.rl"
	{ StartToken(TokenType.Keyword); }
	break;
	case 5:
#line 9 "ScannerDef.rl"
	{ StartToken(TokenType.Identifier); }
	break;
	case 6:
#line 10 "ScannerDef.rl"
	{ StartToken(TokenType.Value); }
	break;
	case 7:
#line 29 "ScannerDef.rl"
	{ SetKeyword(TokenKeyword.Machine); }
	break;
	case 8:
#line 30 "ScannerDef.rl"
	{ SetKeyword(TokenKeyword.State); }
	break;
	case 9:
#line 31 "ScannerDef.rl"
	{ SetKeyword(TokenKeyword.On); }
	break;
	case 10:
#line 32 "ScannerDef.rl"
	{ SetKeyword(TokenKeyword.Enter); }
	break;
	case 11:
#line 33 "ScannerDef.rl"
	{ SetKeyword(TokenKeyword.Exit); }
	break;
	case 12:
#line 34 "ScannerDef.rl"
	{ SetKeyword(TokenKeyword.Run); }
	break;
#line 492 "tmp/Scanner.cs"
		default: break;
		}
	}

_again:
	if ( cs == 0 )
		goto _out;
	if ( ++p != pe )
		goto _resume;
	_test_eof: {}
	_out: {}
	}

#line 113 "Scanner.rl.cs"
         CommitLastToken();
         return _tokens;
      }

      ///<summary>
      /// Call this method after Scan to know if the parser exited prematurely
      /// due to an error.
      ///</summary>
      ///<returns>
      /// A boolean indicating if the Scanner made it to the end of the input or not.
      ///</returns>
      public bool DidReachEndOfInput()
      {
         return (p >= eof);
      }

      /// <summary>
      /// Returns the last characters before an error
      /// </summary>
      public string GetErrorLocation(char[] input, int charCount)
      {
         var end = p;
         var start = p;
         while (start > 0 && end - start < charCount && input[start] != '\n') {
            start--;
         }
         if (input[start] == '\n') {
            start++;
         }

         return "(line " + _lineNumber + "): " + new string(input, start, end - start + 1);
      }
   }
}
